{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f77d097-d27a-4e36-a072-61cf8204430f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (1.26.4)\n",
      "Requirement already satisfied: dlib in /opt/anaconda3/lib/python3.11/site-packages (19.24.0)\n",
      "Requirement already satisfied: pygame in /opt/anaconda3/lib/python3.11/site-packages (2.6.0)\n",
      "Requirement already satisfied: opencv-python==4.6.0.66 in /opt/anaconda3/lib/python3.11/site-packages (4.6.0.66)\n",
      "Requirement already satisfied: opencv-contrib-python==4.6.0.66 in /opt/anaconda3/lib/python3.11/site-packages (4.6.0.66)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/anaconda3/lib/python3.11/site-packages (from opencv-python==4.6.0.66) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install dlib\n",
    "!pip install pygame\n",
    "!pip install opencv-python==4.6.0.66 opencv-contrib-python==4.6.0.66\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8616cf93-7d0c-4a8e-a3a6-605906881b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(cv2.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ffeb73c-042b-4926-bd01-87f6d33ddc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dlib\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95327e07-68d3-45e7-b106-52da56aed9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@170.523] global /private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_11nitadzeg/croot/opencv-suite_1691620374638/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    }
   ],
   "source": [
    "RIGHT_EYE = list(range(36, 42))\n",
    "LEFT_EYE = list(range(42, 48))\n",
    "EYES = list(range(36, 48))\n",
    "\n",
    "frame_width = 640\n",
    "frame_height = 480\n",
    "\n",
    "title_name = 'Drowsiness Detection'\n",
    "\n",
    "face_cascade_name = '/Users/gimseongmin/Downloads/opencv-4.x/data/haarcascades/haarcascade_frontalface_alt.xml' #-- 본인 환경에 맞게 변경할 것\n",
    "face_cascade = cv2.CascadeClassifier()\n",
    "if not face_cascade.load(cv2.samples.findFile(face_cascade_name)):\n",
    "    print('--(!)Error loading face cascade')\n",
    "    exit(0)\n",
    "\n",
    "predictor_file = '/Users/gimseongmin/Downloads/shape_predictor_68_face_landmarks (1).dat' #-- 본인 환경에 맞게 변경할 것\n",
    "predictor = dlib.shape_predictor(predictor_file)\n",
    "\n",
    "status = 'Awake'\n",
    "number_closed = 0\n",
    "min_EAR = 0.25\n",
    "closed_limit = 35  # 눈 감김이 35번 이상일 경우 변수를 넘기고 다시 카운트 시작\n",
    "drowsiness_count = 0  # 졸음 카운트 변수\n",
    "show_frame = None\n",
    "sign = None\n",
    "color = (0, 255, 0)  # 기본 색상 설정\n",
    "\n",
    "def getEAR(points):\n",
    "    A = np.linalg.norm(points[1] - points[5])\n",
    "    B = np.linalg.norm(points[2] - points[4])\n",
    "    C = np.linalg.norm(points[0] - points[3])\n",
    "    return (A + B) / (2.0 * C)\n",
    "\n",
    "def detectAndDisplay(image):\n",
    "    global number_closed\n",
    "    global drowsiness_count\n",
    "    global color\n",
    "    global show_frame\n",
    "    global sign\n",
    "    global status\n",
    "    global RIGHT_EYE\n",
    "    global LEFT_EYE\n",
    "    global EYES\n",
    "\n",
    "    image = cv2.resize(image, (frame_width, frame_height))\n",
    "    show_frame = image\n",
    "    frame_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # CLAHE 적용(컴퓨터 비전 전처리 기법 중 하나, 어두운 곳에서 잘 인식하게 했음.)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    frame_gray = clahe.apply(frame_gray)\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(frame_gray)\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        # 얼굴이 감지되지 않았을 때\n",
    "        cv2.putText(show_frame, \"No face detected\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "        cv2.imshow(title_name, show_frame)\n",
    "        return\n",
    "    \n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "        rect = dlib.rectangle(int(x), int(y), int(x + w), int(y + h))\n",
    "        points = np.matrix([[p.x, p.y] for p in predictor(image, rect).parts()])\n",
    "        show_parts = points[EYES]\n",
    "        right_eye_EAR = getEAR(points[RIGHT_EYE])\n",
    "        left_eye_EAR = getEAR(points[LEFT_EYE])\n",
    "        mean_eye_EAR = (right_eye_EAR + left_eye_EAR) / 2 \n",
    "\n",
    "        right_eye_center = np.mean(points[RIGHT_EYE], axis = 0).astype(\"int\")\n",
    "        left_eye_center = np.mean(points[LEFT_EYE], axis = 0).astype(\"int\")\n",
    "\n",
    "        cv2.putText(image, \"{:.2f}\".format(right_eye_EAR), (right_eye_center[0, 0], right_eye_center[0, 1] + 20),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "        cv2.putText(image, \"{:.2f}\".format(left_eye_EAR), (left_eye_center[0, 0], left_eye_center[0, 1] + 20),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "        \n",
    "        for (i, point) in enumerate(show_parts):\n",
    "            x = point[0, 0]\n",
    "            y = point[0, 1]\n",
    "            cv2.circle(image, (x, y), 1, (0, 255, 255), -1)\n",
    "            \n",
    "        if mean_eye_EAR > min_EAR:\n",
    "            color = (0, 255, 0)\n",
    "            status = 'Awake'\n",
    "            number_closed = number_closed - 1\n",
    "            if number_closed < 0:\n",
    "                number_closed = 0\n",
    "        else:\n",
    "            color = (0, 0, 255)\n",
    "            status = 'sleep'\n",
    "            number_closed += 1\n",
    "\n",
    "        if number_closed >= closed_limit:\n",
    "            drowsiness_count += 1  # 졸음 횟수 증가\n",
    "            number_closed = 0  # 카운트 초기화\n",
    "                     \n",
    "        sign = f'sleep count: {number_closed} / {closed_limit}, drowsiness count: {drowsiness_count}'\n",
    "        break  # 얼굴 하나만 처리\n",
    "\n",
    "    cv2.putText(show_frame, status, (10, 60), cv2.FONT_HERSHEY_DUPLEX, 1, color, 2)\n",
    "    cv2.putText(show_frame, sign, (10, frame_height - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "    cv2.imshow(title_name, show_frame)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "time.sleep(2.0)\n",
    "if not cap.isOpened():\n",
    "    print('Could not open video')\n",
    "    exit(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if frame is None:\n",
    "        print('Could not read frame')\n",
    "        cap.release()\n",
    "        break\n",
    "\n",
    "    detectAndDisplay(frame)\n",
    "    \n",
    "    # q 입력시 종료\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052405b0-e396-427f-be7c-57a54cbebc99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
